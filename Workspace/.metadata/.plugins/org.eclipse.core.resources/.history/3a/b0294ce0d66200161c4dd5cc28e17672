

from keras.layers import Input, Dense, Lambda,merge,Convolution2D,Reshape,MaxPooling2D,UpSampling2D
from keras.layers.noise import GaussianNoise
from keras.models import Model
from keras import backend as K, objectives
from keras.regularizers import l2

class VAE(object):
    def __init__(self,latent_dim,original_dim,intermediate_dim=500,batch_size):
        
        self.batch_size = batch_size
        self.original_dim = original_dim
        self.latent_dim = latent_dim
        intermediate_dim_phono = 500
        
        
        epsilon_std = 0.01
        nb_epoch = 1000
        #l2_value = 0.01
        l2_value = 0
        
        #encoder concepts
        
        input_phono = Input(batch_shape=(batch_size, original_dim_phono))
        #input_phono_corrupted = GaussianNoise(sigma=0.01)(input_phono)
        h_phono = Dense(intermediate_dim_phono,activation="relu",name="layer_h_concept")(input_phono)
        
        z_mean = Dense(latent_dim,name="z_mean")(h_phono)
        z_log_std = Dense(latent_dim,name="z_log_std")(h_phono)
        
        def sampling(args):
            z_mean, z_log_std = args
            epsilon = K.random_normal(shape=(batch_size, latent_dim),
                                      mean=0., std=epsilon_std)
            return z_mean + K.exp(z_log_std) * epsilon
        
        z = Lambda(sampling, output_shape=(latent_dim,),name="layer_z")([z_mean, z_log_std])
        
        #decoder phono
        # we instantiate these layers separately so as to reuse them later
        phono_decoding_layer_intermediate = Dense(intermediate_dim_phono,activation="relu",name="phono_decoding_layer_intermediate")
        phono_decoding_intermediate = phono_decoding_layer_intermediate(z)
        
        phono_decoding_layer_decoded = Dense(original_dim_phono,activation="sigmoid",name="phono_decoding_layer_decoded")
        phono_decoded = phono_decoding_layer_decoded(phono_decoding_intermediate)
        
        
        def vae_loss(input_phono,phono_decoded):
            xent_loss_phono = objectives.binary_crossentropy(input_phono, phono_decoded)
        
            kl_loss = - 0.5 * K.mean(1 + z_log_std - K.square(z_mean) - K.exp(z_log_std), axis=-1)
            return (
                     xent_loss_phono 
                     + kl_loss
                     )
        
        vae = Model([input_phono], [phono_decoded])
        
        """
        COMPILING MODELS
        """
        print("COMPILING MODEL")
        vae.compile(optimizer='Adam', loss=vae_loss)
        
        
        """
        FITTING MODELS
        """
        print("FITTING MODELS")
        print(word_matrices.shape,concepts_oneHots.shape,geo_words.shape)
        vae.fit(x=[word_matrices],
                 y=[word_matrices],
              batch_size=batch_size, nb_epoch=nb_epoch)
        encoder = Model([input_phono], z_mean)
        embeddings = encoder.predict(x=[word_matrices],batch_size=batch_size)